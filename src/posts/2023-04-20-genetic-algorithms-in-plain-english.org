---
title: Build your own Genetic Algorithm
desc: "An introduction to genetic algorithms with an example problem to solve."
image: "./images/blog/genetic_algorithm.jpg"
imageAlt: "Digital drawing of dna."
---

#+begin_center
/[[https://www.freepik.com/free-vector/dna-helix-symbol-isolated-white-background_24085108.htm#query=dna&position=0&from_view=search&track=sph][Image by brgfx]] on Freepik/
#+end_center

/Special thanks to Danny Fekete and his wife, Carolyn Piccinin, for their extensive help with editing and vetting for accuracy. And my partner, Leticia, for her patience in reviewing and her valuable insights./

Years ago, I stumbled upon [[http://www.ai-junkie.com/ga/intro/gat1.html][a tutorial]] on genetic algorithms that ended up being one of the most interesting coding exercises I've ever done. I still think about it often to this day and I want to bring that same joy to others by providing my own explanation of the subject. This tutorial is meant to be approachable by anyone who knows at least one programming language, beginners and experts alike. Doing this exercise is a great a way to practice a new programming language you're learning, improve with one you're already familiar with, or rekindle your passion for programming. Even better, it will also give you a deeper understanding of how evolution works in the real world after simulating it in code.

/[Change this?]/ Throughout this tutorial, I'm going to be using terms from the discourse of natural selection and genetics. You do not need to understand the terms in order to follow along. If you want to learn more about how these things work in the real world, check out [[https://neckdeep.dev/][this article]] by [[https://neckdeep.dev/][Danny Fekete]]. First, I'm going to explain the general steps of a standard genetic algorithm. Then, and this is the fun part, I'm going to outline a problem to solve so you can start coding right away! Your resulting program only needs to take a single number as input and print a string as output, so it can have a simple command-line user interface or you can make a fancy web UI---it's up to you how far you want to take it.

* Approaching the Genetic Algorithm

#+begin_center
/*This section was written by Danny Fekete. He has an extended version of this topic on his blog that you should shouldn't miss. It's packed with valuable insights. Read it here: <link>*/
#+end_center

/[Re-write this? It seems to repeatedly fall into the fitness tautology trap.]/

Very broadly, *genetic algorithms* attempt to mimic principles of natural selection and genetics to build optimal solutions to problems.  They involve generating lots of randomized approaches, evaluating those approaches for their +degrees of success+, and then preferentially selecting and combining the best attempts (while discarding the worst) to see if the resulting subsequent batch contains solutions that are even better.  Rinse and repeat, sprinkling in degrees of randomness and predictability to taste, until a successful solution, or a solution with a desired degree of +efficiency+ performance(?), is +achieved+ found.

Because this strategy of solution-building is inspired by---and heavily adopts the metaphors of---academic fields outside of computer science, having a baseline understanding of those fields (and their terminology) should make trying to implement your own genetic algorithms much more intuitive.  So, here you go!

** Natural Selection

/[Remove unneeded history lesson? I want this information to be more concise.]/

Charles Darwin and Alfred Russel Wallace described the process of "Evolution by Natural Selection" as a way to make sense of both the stunning variation across organisms seen in the natural world, as well as the subtle but unavoidable patterns that exist between them.  *Evolution* (i.e., change over time) of species had been theorized before Darwin's time, but lacked a plausible (observable, eventually testable) engine or mechanism.  Natural +Selection+ selection was the proposed mechanism, and demonstrated that the abundant variety of life we observe would emerge directly and necessarily from the interaction between a few simple, acknowledged principles:

/[The framework given here, while very interesting, doesn't synchronize well with the genetic algorithm.]/

- *Heredity:* Offspring tend to resemble some combination of their parents (and diminishingly, their more distant ancestors).
- *Mutation:* Novel or modified characteristics occasionally show up that do not appear to have belonged to an ancestor, but may still be passed on to offspring as normal.
- *Competition:* Because resources are limited and typically insufficient to fully satisfy all members of a given population, not all members will reproduce equally---some will die before they become parents, some will thrive and have lots of offspring. /[Is having limited resources the sole reason for competition? What about insufficient defense against predators?]/
  - Competitive advantage as described by an interaction of an organism's traits with its environment is often called *fitness* (as a classic example, if a giraffe having a longer neck means access to more leaves on the local trees than fellow giraffes, and better access to leaves is demonstrated to represent a lower likelihood of dying before it reproduces, the giraffe could be said to be "more fit"). /[Even this example doesn't make me think that having limited resources is the problem. There are enough leaves for all the giraffes, but the giraffes that can't reach them die off.]/

Accepting these principles as plausible features of nature, we can anticipate some overarching consequences by exploring interactions between them:

- *Heredity with Mutation* suggests that a population has a capacity for change beyond just an endless recombination of preexisting traits.
- *Heredity with Competition* suggests that the winners---those able to become parents before they die---will create a new generation that tends to more resemble themselves.  Conversely, traits characteristic of the losers---those who died before they reproduced---will fade from the population through subsequent generations.
- *Mutation with Competition* suggests that occasionally a novel trait will arise that confers a competitive advantage (i.e., the organism that has that new trait is better able to survive and +attract+ acquire a mate to reproduce because of it).  These traits will then enter and proliferate across the population through subsequent generations.

That's it!  In broad strokes, that engine---the consistent interaction of heredity, mutation, and competition---is the explanation for how the traits of populations change over time, or /evolve/.  It's called "/Natural/ Selection" because the "choice" of which individual organisms survive and which traits proliferate isn't made by anyone or anything, but is a /natural/ consequence of individual fitness.[fn:1]

** Genetics

While natural selection operates at the level of populations, genetics concerns itself with individual members of those populations; some of the foundational ideas are represented in the following terms (organized to work our way from the observable individual organism down to the molecular medium of its heredity):
- *Organism:* a discrete entity made up of one or more cells, each of which typically contains an identical copy of a genome (described next).
  - Organisms with enough features in common to be able to mate and produce viable offspring (i.e., child organisms that can similarly mate and produce viable offspring) are said to be *members of the same species.*[fn:2]
  - A group of organisms that are members of the same species /and/ are sufficiently local to each other that they can interbreed and compete for the same resources can be said to be *a population.* /[Do the resources need to be mentioned?]/
  - Grouping all currently-breeding parents (or the offspring of all currently-breeding parents) within a population into a cohort is the process of describing *generation.*  Generations in nature often have fuzzy boundaries, but can be conceptually useful as units for tracking the evolution of traits over time.
- *Genome:* the complete set of data that represents an organism's heritable features.  In humans, this would be encoded in the full set of an individual's DNA.
  - *Analogy:* An individual's genome is like the information content in a complete encyclopaedia.
  - Identical twins have identical genomes.
- *Chromosome:* a subdivision of an individual's genome into a discrete package.  (Humans typically have their genomes packaged into 23 chromosomes in any given cell)
  - *Analogy:* An individual's complete set of chromosomes is like a complete set of the volumes of an encyclopaedia.
- *Gene:* a sequence of nucleotides (see the next term) located on an expected part of a chromosome that represents the instructions for building a particular configuration of protein (and ultimately contributes to the expression of a particular observable trait). /[The mention of protein only adds to confusion, at least for me.]/
  - *Analogy:* An individual's genes are like the individual words in an encyclopaedia.  Typically, the presence of /multiple/ specific genes interact together to contribute to a given trait, like multiple specific words creating meaning in a sentence.
  - *Genes can be viewed as the unit of heredity:* when parents produce offspring through sexual reproduction, those offspring contain a combination of DNA (and ultimately, fitness-impacting genes) drawn from the parents.  If the offspring eventually become parents themselves, those same genes will have a chance to travel to the subsequent generation, and so on.[fn:3] /[Is the mention of DNA helpful here?]/
- *Allele:* the specific version of a gene (selected from the set of all possible, valid genes) that could occupy a given location on a chromosome.  The version present determines how, or which variety of a given trait is ultimately expressed.
  - *Analogy:* The alleles present that govern an individual's actual eye colour are like the adjectives chosen to drive meaning in the sentence, "Pineapple is a `[ heroic \ tragic \ confusing \ alarming ]` choice for a pizza topping." /[I like the adjectives analogy, but I find it confusing to relate it to the eye colour example.]/
- *Nucleotide:* one of a set of complex molecules (nucleic acids) that can be linked together to form DNA.  The sequence in which these molecules occur /is/ the data which is copied and passed on in part to offspring, and could therefore be considered the fundamental matter of heredity.
  - *Analogy:* The nucleotides linked together into an organism's DNA is like the individual letters in the words in the sentences in the articles in the volumes that make up a complete encyclopaedia.

When discussing an organism's traits in genetic terms, it's helpful to know whether we're working at the scale of the generally observable, or at the scale of the genes that create them.  Two more terms are good to have handy, to this end:
- *Phenotype:* an observable, heritable trait of an individual organism.
  - Eye colour is an example of phenotype; which languages are spoken by the organism is /not/ an example of phenotype.[fn:4]
- *Genotype:* the specific genes possessed by an individual that are responsible for the expression of an observable, heritable trait.
  - The presence of specific alleles of eye-colour-coding genes in an individual's genome is its eye-colour /genotype/; these will ultimately interact to result in the /phenotype/ of having an associated eye colour.

* A Standard Genetic Algorithm

Very broadly, *genetic algorithms* attempt to mimic principles of natural selection and genetics to find optimal solutions to problems. The overall idea is, given a target problem, we're going to encode potential solutions to the problem. Thinking of these potential solutions as *organisms*, we'll simulate natural selection, allowing them to evolve into better solutions, and then hopefully leaving us with the kind of great solution we were looking for.

The kinds of problems genetic algorithms are well-suited for are problems in which we know what a good solution would look like, but can't easily come up with one ourselves. Some use-cases are: the [[https://en.wikipedia.org/wiki/Travelling_salesman_problem][travelling salesman problem]], employee shift scheduling (e.g., the [[https://en.wikipedia.org/wiki/Nurse_scheduling_problem][nurse scheduling problem]]), and [[https://en.wikipedia.org/wiki/List_of_genetic_algorithm_applications][many more]].

In this tutorial, I'm going to describe a /standard/ genetic algorithm, which is easy to code and also recommended by experts. The idea is, once you understand how to code this version of a genetic algorithm, when you have a new problem to solve, you can attempt to apply this algorithm as-is or make modifications to the steps as needed.

#+begin_quote
Start by using an "off the shelf" GA (genetic algorithm). It is pointless developing a complex GA, if your problem can be solved using a simple and standard implementation.

-- Sastry, K., Goldberg, D., Kendall, G. (2005). [[https://doi.org/10.1007/0-387-28356-0_4][Genetic Algorithms]].
#+end_quote

Before we dive into details, here's a high-level overview of the steps of the algorithm:

- *Planning:* Before writing any code, we need to answer the question: /How do we encode a potential solution to the target problem?/
- *Setting parameters:* There are a few key parameters that need to be set, which will heavily influence the performance of the algorithm each time we run it.
- *Create initial population:* The first population of organisms is created.
- *Fitness evaluation:* The fitness of each organism in the entire population is evaluated.
- *Selection:* Two organisms are selected as parents to reproduce.
- *Crossover:* The parents produce two offspring by potentially undergoing /crossover/.
- *Mutation:* Some genes in the offspring might get mutated.
- *Replace population:* When there's enough offspring to form a new population, the old population gets replaced.
- *Pick the winner:* The fittest organism in the remaining population is your solution!

#+begin_center
[[file:images/blog/genetic_algorithm/genetic_algorithm_flow.svg]]
#+end_center

** Step 1. Planning

The first step towards building your own genetic algorithm for a target problem is to plan how potential solutions to the problem will be encoded as organisms. More specifically, how to represent genes and chromosomes, and how to evaluate the fitness of an organism.

Breaking it down from the top, each *organism* will only be made up of a single *chromosome*, so the two terms are often interchangeable. (This also means an organism's entire genome and DNA will be encoded in its one-and-only chromosome, which makes things much simpler than with most real organisms.) All of the information for a potential solution must be encoded in this chromosome.

As in nature, a chromosome is made up of *genes*, which are like numbered containers for information. Unlike in nature, our chromosomes should all be the same length (i.e., they should contain the same number of genes). This is necessary in order for the /crossover/ step to work as it is described in Step 6.

Each gene's information only has so many possible variations. A particular version of a gene is called an *allele*. Breaking down this last piece, an allele is made up of *nucleotides* (the building blocks of DNA), which are equivalent to units of information. In our code, each nucleotide will be represented by one *bit* (~0~ or ~1~), since this is the smallest piece of information on a computer.

/[Might need to remove this, after trying Danny's idea of different genes (numbers and operators) for the example problem.]/ For this standard algorithm and the problems discussed in this tutorial, each gene will have the same possible variations because the positions don't matter. So, there is only one set of possible alleles.

/[This would be removed too.]/ Every gene should be the same size, which is determined by the number of possible alleles needed for the target problem. For example, if you choose genes to be 3 bits in length, that gives

#+begin_center
*(size of bit)^(size of gene) = 2^3 = 8*
#+end_center

different possible values for any single gene. (The size of a bit is always 2, since there are only two possible values: ~0~ or ~1~.)

Each organism's *phenotype* should be a potential solution to the operating problem. For instance, if the expected solution to an operating problem is an English word, each gene in that organism could be expressed as a letter (e.g., "d"). The combined result of its genes would be its phenotype: a string of letters (e.g., "dwnlode").

To allow for 26 characters, we would need genes to be at least 5 bits in length (2^5 would give us the necessary headroom of 32 possible alleles):

#+begin_export html
<div class="table-container">
#+end_export
| allele  | value  |
|---------+--------|
| ~00001~ | ~a~    |
| ~00010~ | ~b~    |
| ~00011~ | ~c~    |
| ...     | ...    |
| ~11010~ | ~z~    |
#+begin_export html
</div>
#+end_export

Here's a breakdown of an example chromosome that could be used for that kind of word-based operating problem:

#+begin_center
[[file:images/blog/genetic_algorithm/chromosome_explanation.svg]]
#+end_center

The first gene in the above chromosome has the allele that represents the value "a".

Now for fitness. For whatever problem we want our algorithm to solve, we need to know what a good solution looks like because we need some way of knowing which organisms are better than others. The idea here is to come up with a way to *evaluate* each organism and give it a *fitness* score (a decimal number). The higher the fitness score, the closer the organism is to an ideal solution. It's difficult to be more descriptive than this because fitness evaluation varies a lot depending on the problem, so I'll explain by example.

Let's say the target problem is to find the best values for ~a~, ~b~, ~c~, and ~d~ in the equation ~a + 2b + 3c + 4d = 30~.[fn:5] Each organism's phenotype is its particular values for ~a~, ~b~, ~c~, and ~d~. The fitness evaluation for this problem could be:

#+begin_center
#+begin_example
1 / (abs((a + 2b + 3c + 4d) - 30) + 1)
#+end_example
#+end_center

Where ~abs~ gives the absolute value of a number. This evaluation is designed to give a higher fitness score for better values, with 1 being a perfect score. The range is ~(0, 1]~, meaning from 0 (exclusive) to 1 (inclusive).

So, an organism with the values ~a = 0~, ~b = 0~, ~c = 10~, and ~d = 0~ would have a fitness of 1...

#+begin_center
#+begin_example
1 / (((a + 2b + 3c + 4d) - 30) + 1)
= 1 / (((0 + 2(0) + 3(10) + 4(0)) - 30) + 1)
= 1 / (0 + 1)
= 1
#+end_example
#+end_center

...which is a perfect score! This makes sense, because these values perfectly satisfy the target equation.

#+begin_center
#+begin_example
a + 2b + 3c + 4d = 30
0 + 2(0) + 3(10) + 4(0) = 30
30 = 30
#+end_example
#+end_center

** Step 2. Setting parameters

The algorithm has four major parameters that must be set. These will affect how well the algorithm performs each time it runs on a target problem. Once you've finished implementing your algorithm, these are the parameters you'll want to play with and see how it performs differently.

*** Population size

This is the number of organisms in the population for each generation. We'll call this parameter ~populationSize~.

A good starting point is ~populationSize = 50~.

*** Crossover rate

As pairs of organisms are selected to reproduce for the next generation, they may produce exact copies or be combined (like sexual reproduction in the real world). The crossover rate is the *probability* that each pair of selected organisms will be crossed over, which will be explained in Step 6. We'll call this parameter ~crossoverRate~.

A good starting point is ~crossoverRate = 0.6~.

*** Mutation rate

Every bit of information in every chromosome has a (low) chance to be mutated, which will be explained in Step 7. Mutations can spark new traits that can then be carried to future generations, adding diversity to the population. We'll call this parameter ~mutationRate~.

A good starting point is ~mutationRate = 0.05~.

*** Stopping condition

At some point, the algorithm has to stop, otherwise you've created an infinite loop! The easiest stopping condition to implement is to set a limit on the *number of generations*. When the limit is reached, take the organism with the highest fitness from the last generation's population and you have a solution!

Alternately, you could let the stopping condition be a *fitness threshold*. When a organism's fitness meets the threshold, halt and deem it the winner!

** Step 3. Create initial population

The first generation of organisms needs to come from somewhere. A good way to make the first population is to randomly generate every bit of information in every organism's chromosome until the number of organisms is equal to ~populationSize~. That way, all the organisms in the population will have completely random genes.

** Step 4. Fitness evaluation

Let the games begin! Evaluate the fitness of every organism in the population and store this information to be used in the next step.[fn:6]

** Step 5. Selection

This step begins the reproduction process (along with the next two steps). The current population needs to be used to form a new population (the next generation). Essentially, we're going to select pairs of organisms from the current population and have them reproduce to form offspring. Each pair will produce two offspring, and once we have enough offspring (determined by ~populationSize~), they will replace the current population.

Since the goal of the algorithm is to work towards a better solution, this step is where we simulate competition. In nature, not all members will reproduce equally---some will thrive and have lots of offspring while others will be less successful by comparison (due to death, inability to find a mate, etc.). Instead of just selecting organisms at random, the probability that an organism is selected should be proportional to its fitness. After all, this is the purpose of an organism's fitness! It should be more likely for high-performing organisms to be selected for reproduction than their lower-performing peers. For this, we're going to use the *roulette wheel* strategy.

Let's say we have a population of five organisms:

#+begin_export html
<div class="table-container">
#+end_export
| Organism                                              | Chromosome  | Fitness | Percent of population fitness |
|-------------------------------------------------------+-------------+---------+-------------------------------|
| @@html:<span style="color:#9933FF">&#9632;</span>@@ 1 | ~0011 0110~ |    0.23 |                          9.9% |
| @@html:<span style="color:#333333">&#9632;</span>@@ 2 | ~0001 1010~ |    0.68 |                         29.2% |
| @@html:<span style="color:#61C0FF">&#9632;</span>@@ 3 | ~1001 1011~ |     0.1 |                          4.3% |
| @@html:<span style="color:#17C22E">&#9632;</span>@@ 4 | ~1010 0111~ |    0.95 |                         40.8% |
| @@html:<span style="color:#EB0000">&#9632;</span>@@ 5 | ~0101 0010~ |    0.37 |                         15.9% |
#+begin_export html
</div>
#+end_export

(Don't pay much attention to the chromosome values in this example. I made them up randomly.)

At a casino, every segment of a roulette wheel is equal in size. But our goal is to make a rigged roulette wheel where the segments are proportional to their fitness:

#+begin_center
[[file:images/blog/genetic_algorithm/genetic_algorithm_roulette.png]]
#+end_center

Now, when we spin the wheel to select an organism, it's obvious there will be a bigger chance to land on *organism 4* than any other organism.

If you want more direct instructions on implementing the roulette wheel strategy in code, click/tap below. Or, you can enjoy devising the algorithm on your own!

#+begin_export html
<details>
<summary>Show roulette wheel instructions</summary>
#+end_export

To implement roulette wheel selection in code, this is what you need to do:

- (Your organisms must be kept in order. The way they're ordered doesn't matter, so long as the order doesn't change.)
- Calculate the total fitness of the population (sum the fitnesses of all organisms).
- Calculate the cumulative fitness of each organism. The cumulative fitness of an organism is its fitness plus the sum of the fitnesses of all the organisms before it.
- Generate a random number, ~r~, between 0 (exclusive) and the total fitness (inclusive).
- Find the first organism whose cumulative fitness is greater than or equal to ~r~.

For example, if we calculate the cumulative fitnesses of our organisms...

#+begin_export html
<div class="table-container">
#+end_export
| Organism | Chromosome  | Fitness | Cumulative fitness |
|----------+-------------+---------+--------------------|
|        1 | ~0011 0110~ |    0.23 |               0.23 |
|        2 | ~0001 1010~ |    0.68 |               0.91 |
|        3 | ~1001 1011~ |     0.1 |               1.01 |
|        4 | ~1010 0111~ |    0.95 |               1.96 |
|        5 | ~0101 0010~ |    0.37 |               2.33 |
#+begin_export html
</div>
#+end_export

...and if ~r~ turns out to be 1.89, that means we select *organism 4*.

#+begin_center
[[file:images/blog/genetic_algorithm/roulette_wheel_cumulative.svg]]
#+end_center

#+begin_export html
</details>
#+end_export

We have now met the overall goal of this step: to *select two organisms while accounting for their fitness*, which will be used in the next step to produce a pair of offspring.[fn:7]

** Step 6. Crossover

In this step, we'll be emulating an important aspect of natural selection: heredity. Offspring tend to resemble some combination of their parents (and diminishingly, their more distant ancestors). We're going to accomplish this through reproduction by breeding or cloning.

The offspring of the two selected organisms will either inherit a combination of their traits (genes from both parents) or be clones of the parents.

To check if a crossover should happen, generate a random number, ~r~, between 0 and 1. If ~r~ is less than or equal to ~crossoverRate~, perform a crossover. Otherwise, let the offspring be exact copies of the parents. /[Rephrase this for precision? The two offspring should be the same as the two parents.]/

To crossover two organisms, pick a random position between the genes of a chromosome and swap all the alleles to the right in the first chromosome with the corresponding alleles in the second chromosome. (Remember, our chromosomes are supposed to contain the same number of genes, so this makes it easy to line them up and cut them at the same spot.)

#+begin_center
[[file:images/blog/genetic_algorithm/crossover.svg]]
#+end_center

** Step 7. Mutation

For each bit in each offspring's chromosome:

- Generate a random number, ~r~, between 0 and 1.
- If ~r~ is less than or equal to ~mutationRate~, mutate the bit. To mutate, simply flip the bit (~0~ to ~1~, or ~1~ to ~0~).

** Step 8. Replace population

Steps 5 to 7 (selection, crossover, and mutation) taken as a cycle together form the reproduction process. Each cycle produces two offspring. We need to repeat the cycle until we get enough offspring to form a new population (~populationSize~), which replaces the old population. The old population won't be needed anymore (everything dies...). (For practical purposes, this means offspring never reproduce with the previous generation.)

** Step 9. Repeat until the stopping condition is met

Steps 4 to 8 form the main loop of the algorithm. Each iteration of that loop is one generation. The end of the loop is determined by the stopping condition, which leaves us with the last generation's population. If the stopping condition is a limit on the number of generations, say 100, then we simply stop after repeating 100 iterations.

** Step 10. Pick the winner

In the remaining population, pick the organism with the highest fitness. There's your solution!

* A Target Problem

As with anything in programming, you're not going to understand this simply by reading. You need to try implementing a genetic algorithm for yourself. But first, you need the right kind of problem to solve. Lucky for you, I've got that part covered. In this section, I'm going to outline a problem and give you all the details you need so you can start coding in any programming language you want. In other words, I'm going to cover *Step 1* (planning) and you have to do the rest.

** The Problem

Given a target number, find a human-readable string of single-digit numbers and basic arithmetic operators that equals that number. For example, if the target number is ~10~, some solutions would be:

- ~5 + 5~
- ~5 * 2~
- ~5 + 5 + 1 - 1 - 5 - 5 + 1 + 9 * 1 / 1~

*Note:* Because the solutions should take the form of math strings, you should decide how those strings get evaluated. For example, they could be evaluated left-to-right or use the standard order of operations (multiplication > division > addition > subtraction). Feel free to choose whichever evaluation method is easier for you to implement.

If we solve this problem using a genetic algorithm, since all of the above solutions equal 10 exactly, they would all be ideal matches and maximally fit. Of course, there are infinite possible solutions to reach any target number, and because our initial population is randomly generated, the algorithm may not discover /any/ of them in the limited time it has to run. So, the true goal of our genetic algorithm would be to give us the best candidate after a certain number of generations.

** Implementing Step 1. Planning

Since a potential solution is to be a string of single-digit numbers and arithmetic operators, that is exactly what a chromosome should represent. The genes, being pieces of a chromosome, should therefore each express a single-digit number or an arithmetic operator.

Now, instead of artificially forcing organisms to have alternating numbers and operators, let's allow any combinations of valid genes and instead do a sort of /clean up/ when evaluating their expression. In other words, ignore successive numbers (or operators) in a row, using only the first one that appears in order while alternating. For example, ~6 6 * 8 1 + 5 6 9 / 2 1~ /cleans up/ to be ~6 * 8 + 5 / 2~.

To determine gene size, we need to know how many possible alleles are necessary. In this case, the required alleles are all the single-digit numbers and arithmetic operators: ~0~, ~1~, ~2~, ~3~, ~4~, ~5~, ~6~, ~7~, ~8~, ~9~, ~+~, ~-~, ~*~, ~/~. That's fourteen possible alleles in total, so we need a minimum of four bits per gene (giving us 2^4 = 16 different possible alleles). We will have two left over alleles, but we can ignore them if they turn up in the resulting chromosome. So, our alleles are:

#+begin_export html
<div class="table-container">
#+end_export
| allele | value       |
|--------+-------------|
| ~0000~ | ~0~         |
| ~0001~ | ~1~         |
| ~0010~ | ~2~         |
| ~0011~ | ~3~         |
| ~0100~ | ~4~         |
| ~0101~ | ~5~         |
| ~0110~ | ~6~         |
| ~0111~ | ~7~         |
| ~1000~ | ~8~         |
| ~1001~ | ~9~         |
| ~1010~ | ~+~         |
| ~1011~ | ~-~         |
| ~1100~ | ~*~         |
| ~1101~ | ~/~         |
| ~1110~ | ~(junk)~ |
| ~1111~ | ~(junk)~ |
#+begin_export html
</div>
#+end_export

As an example, we could have the following organism's chromosome and its phenotype:

#+begin_center
#+begin_example
[0110 0110 1110 1100 1000 0001 1010 0101 0110 1001 1101 0010 0001]
= 6 6 (junk) * 8 1 + 5 6 9 / 2 1
= 6 * 8 + 5 / 2
= 50.5
#+end_example
#+end_center

Now, we need to determine how the fitness of an organism should be evaluated. Recall that that we need an evaluation function which produces a higher number for organisms that are closer to the ideal solution. Ideally, we should fit the fitness number into the range ~(0, 1]~, since this makes the roulette wheel selection easier. Try to come up with this function yourself, or click/tap to see my suggestion below.

#+begin_export html
<details>
<summary>Show fitness function</summary>
#+end_export

~fitness(phenotype) = 1 / abs((target - phenotype) + 1)~

Where ~phenotype~ is the evaluated expression of a given organism, ~target~ is the target number, and ~abs~ gives the absolute value of a number.

#+begin_export html
</details>
#+end_export

*Gotcha:* It is very possible for division by 0 to be part of a phenotype. I'll leave it up to you to decide how to handle it, but do expect it to happen and consider your options.

** Build it!

That's it! Now you're on your own to code this algorithm by implementing steps 2 through 10. In the end, you should have an app that asks for a target number and then gives a math expression for that number. Remember, if you're not getting good results, try tweaking the parameters.

* Food for Thought

** Why a chance of crossover?

Why is it important to have a chance of crossover /not/ happening? Suppose we have two organisms, Alice and Bob, selected to be parents. Alice's fitness is 99% and Bob's is 80%. If Alice and Bob are to produce offspring who inherit from both of them, the offspring are almost guaranteed to have a lower fitness than Alice's 99%. A preferable outcome would be for Alice's offspring to /exclusively/ contain her genes---without any crossover with Bob---resulting in a clone. (That final percentage point of fitness might be then achieved with a lucky mutation.)

** Selecting the same chromosome more than once?

/[To-do]/

** What does cloning represent?

When a crossover doesn't occur, the offspring are clones of the parents. What does it mean to produce clones? Are we simulating an organism that reproduces both sexually /and/ asexually? Or are we representing organisms that simply carry on living into the next generation?

** What are the traits?

In the real world, organisms can be described as having many traits. In the target problem described above, what are the traits of an organism? Do each of our organisms only have a single trait: its evaluated number? Or can we think of each expressed allele as a trait?

** When does crossover help?

In the target problem described above, does crossing over two high-fitness organisms have a good chance of producing high-fitness offspring? Swapping genes seems likely to drastically, and almost randomly, change a organism's phenotype. It seems more like mutating a chunk of a chromosome than inheriting traits.

* Footnotes

[fn:1] Conversely, *artificial* selection occurs when populations are bred with intention to encourage or discourage particular traits (and therefore, "fitness" is externally, deliberately dictated).  Dog breeds and the modern forms of the fruits and vegetables we eat are classic examples of artificial selection.  (Incidentally, artificial selection in humans is called [[https://en.wikipedia.org/wiki/Eugenics][eugenics]], and is an endlessly fascinating ethical tire-fire.)

[fn:2] Species in nature are not as distinct as they're often presented and described, since "viability" of offspring can be a matter of degree (excluding cases like mules---horse/donkey hybrids that are born sterile), and can be subject to geographical boundaries.  One of the coolest examples I've encountered is the idea of [[https://en.wikipedia.org/wiki/Ring_species][ring speciation]]: imagine a migrating population that arrives at an impassible barrier like a lake or a mountain, and begins to spread around it.  Over multiple generations, local portions of that larger population will be subject to different selection pressures, resulting in local variations building up (and associated, accumulating genetic differences when comparing parts of the population that went one way when it met the barrier, vs. the other).  If the expanding population meets up again on the other side of the barrier (i.e., "closing the ring"), it's possible that members of the two sides will have built up enough differences that they'll no longer be genetically compatible with one another---/they'll be different species, by this definition/.  Yet, if you were to take sample organisms at smaller geographic intervals, travelling back around that ring from one end to the other, they /would/ be able to interbreed.  Speciation as a gradient!  I love it.

[fn:3] Richard Dawkins, before his association with atheism, arguably became a household name for his book /The Selfish Gene/, wherein he explored a fascinating extension of this process and imagined the machinery of organisms---cells, blood, eyes, locomotion, intelligence, tentacles, etc.---as mere vehicles for individual genes to improve their chances of propagation.  It was a fun read, and pre-Creationist-beleaguered Dawkins had a spark of eager excitement that came out in his footnotes especially, that I think the vagaries of the world eventually ground away.  Alas.

[fn:4] /Capacity/ to speak a language /largely/ is (i.e., no cactus is likely to ever speak Urdu no matter how much expert tutelage it has access to, while humans do it all the time); /capacity to speak a language comparatively well/ is extremely complicated, increasingly becoming an interaction between the individual's heredity and its lived experience...

[fn:5] Example borrowed from: Hermawanto, D. (2013). Genetic algorithm for solving simple mathematical equality problem. arXiv preprint [[https://arxiv.org/pdf/1308.4675.pdf][arXiv:1308.4675]].

[fn:6] This is arguably an implementation detail pertaining to optimization via caching, but I see it as having conceptual importance. The fitness of an organism never changes because its genetics don't change and the operating problem doesn't change. This is different from how we might talk about people's physical fitness, where you can become more fit by working out. Since we're simulating natural selection and treating environmental factors as being constant, fitness is tied to the genetics of an organism, which are fixed. The only changes to genetics happen between generations (i.e., during reproduction). So, with fitness being an unchanging value of an organism, it should be evaluated exactly once per organism.

[fn:7] Note that this allows for the same organism to be selected more than once. That's okay! Organisms with higher fitness being allowed to reproduce multiple times is part of natural selection. Less fit individuals may not be selected to breed at all, allowing their less-desirable traits to simply die out.

[fn:9] Goldberg, David (1989). Genetic Algorithms in Search, Optimization and Machine Learning. Reading, MA: Addison-Wesley Professional. ISBN 978-0201157673.

[fn:8] https://en.wikipedia.org/wiki/Genetic_algorithm#History
