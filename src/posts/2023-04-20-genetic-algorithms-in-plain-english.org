---
title: Build your own Genetic Algorithm
desc: "An introduction to genetic algorithms with an example problem to solve."
image: "./images/blog/genetic_algorithm.jpg"
imageAlt: "Digital drawing of dna."
---

#+begin_center
/[[https://www.freepik.com/free-vector/dna-helix-symbol-isolated-white-background_24085108.htm#query=dna&position=0&from_view=search&track=sph][Image by brgfx]] on Freepik/
#+end_center

/Special thanks to Danny Fekete and his wife, Carolyn Piccinin, for their extensive help with editing and vetting for accuracy. And my partner, Leticia, for her patience in reviewing and her valuable insights./

Years ago, I stumbled upon [[http://www.ai-junkie.com/ga/intro/gat1.html][a tutorial]] on genetic algorithms that ended up being one of the most interesting coding exercises I've ever done. I still think about it often to this day and I want to bring that same joy to others by providing my own explanation of the subject. This tutorial is meant to be approachable by anyone who knows at least one programming language, beginners and experts alike. Doing this exercise is a great a way to practice a new programming language you're learning, improve with one you're already familiar with, or rekindle your passion for programming. Even better, it will also give you a deeper understanding of how evolution works in the real world after simulating it in code.

I'm going to start by explaining the general steps of a standard genetic algorithm. Afterwards, and this is the fun part, I'm going to outline a problem to solve so you can start coding right away! Your resulting program only needs to take a single number as input and print a string as output, so it can have a simple command-line user interface or you can make a fancy web UI---it's up to you how far you want to take it.

/[Change this?]/ Throughout this tutorial, I'm going to be using terms from the discourse of natural selection and genetics. You do not need to understand the terms in order to follow along. If you want to learn more about how these things work in the real world, check out [[https://neckdeep.dev/][this article]] by [[https://neckdeep.dev/][Danny Fekete]].

* A Standard Genetic Algorithm

Very broadly, *genetic algorithms* attempt to mimic principles of natural selection and genetics to find optimal solutions to problems. The overall idea is, given a target problem, we're going to encode potential solutions to the problem. Thinking of these potential solutions as *organisms*, we'll simulate natural selection, allowing them to evolve into better solutions, and then hopefully leaving us with the kind of great solution we were looking for.

The kinds of problems genetic algorithms are well-suited for are problems in which we know what a good solution would look like, but can't easily come up with one ourselves. Some use-cases are: the [[https://en.wikipedia.org/wiki/Travelling_salesman_problem][travelling salesman problem]], employee shift scheduling (e.g., the [[https://en.wikipedia.org/wiki/Nurse_scheduling_problem][nurse scheduling problem]]), and [[https://en.wikipedia.org/wiki/List_of_genetic_algorithm_applications][many more]].

In this tutorial, I'm going to describe a /standard/ genetic algorithm, which is easy to code and also recommended by experts. The idea is, once you understand how to code this version of a genetic algorithm, when you have a new problem to solve, you can attempt to apply this algorithm as-is or make modifications to the steps as needed.

#+begin_quote
Start by using an "off the shelf" GA (genetic algorithm). It is pointless developing a complex GA, if your problem can be solved using a simple and standard implementation.

-- Sastry, K., Goldberg, D., Kendall, G. (2005). [[https://doi.org/10.1007/0-387-28356-0_4][Genetic Algorithms]].
#+end_quote

Before we dive into details, here's a high-level overview of the steps of the algorithm:

- *Planning:* Before writing any code, we need to answer the question: /How do we encode a potential solution to the target problem?/
- *Setting parameters:* There are a few key parameters that need to be set, which will heavily influence the performance of the algorithm each time we run it.
- *Create initial population:* The first population of organisms is created.
- *Fitness evaluation:* The fitness of each organism in the entire population is evaluated.
- *Selection:* Two organisms are selected as parents to reproduce.
- *Crossover:* The parents produce two offspring by potentially undergoing /crossover/.
- *Mutation:* Some genes in the offspring might get mutated.
- *Replace population:* When there's enough offspring to form a new population, the old population gets replaced.
- *Pick the winner:* The fittest organism in the remaining population is your solution!

#+begin_center
[[file:images/blog/genetic_algorithm/genetic_algorithm_flow.svg]]
#+end_center

** Step 1. Planning

The first step towards building your own genetic algorithm for a target problem is to plan how potential solutions to the problem will be encoded as organisms. More specifically, how to represent genes and chromosomes, and how to evaluate the fitness of an organism.

Breaking it down from the top, each *organism* will only be made up of a single *chromosome*, so the two terms are often interchangeable. (This also means an organism's entire genome and DNA will be encoded in its one-and-only chromosome, which makes things much simpler than with most real organisms.) All of the information for a potential solution must be encoded in this chromosome.

As in nature, a chromosome is made up of *genes*, which are like numbered containers for information. Unlike in nature, our chromosomes should all be the same length (i.e., they should contain the same number of genes). This is necessary in order for the /crossover/ step to work as it is described in Step 6.

Each gene's information only has so many possible variations. A particular version of a gene is called an *allele*. Breaking down this last piece, an allele is made up of *nucleotides* (the building blocks of DNA), which are equivalent to units of information. In our code, each nucleotide will be represented by one *bit* (~0~ or ~1~), since this is the smallest piece of information on a computer.

/[Might need to remove this, after trying Danny's idea of different genes (numbers and operators) for the example problem.]/ For this standard algorithm and the problems discussed in this tutorial, each gene will have the same possible variations because the positions don't matter. So, there is only one set of possible alleles.

/[This would be removed too.]/ Every gene should be the same size, which is determined by the number of possible alleles needed for the target problem. For example, if you choose genes to be 3 bits in length, that gives

#+begin_center
*(size of bit)^(size of gene) = 2^3 = 8*
#+end_center

different possible values for any single gene. (The size of a bit is always 2, since there are only two possible values: ~0~ or ~1~.)

Each organism's *phenotype* should be a potential solution to the operating problem. For instance, if the expected solution to an operating problem is an English word, each gene in that organism could be expressed as a letter (e.g., "d"). The combined result of its genes would be its phenotype: a string of letters (e.g., "dwnlode").

To allow for 26 characters, we would need genes to be at least 5 bits in length (2^5 would give us the necessary headroom of 32 possible alleles):

#+begin_export html
<div class="table-container">
#+end_export
| allele  | value  |
|---------+--------|
| ~00001~ | ~a~    |
| ~00010~ | ~b~    |
| ~00011~ | ~c~    |
| ...     | ...    |
| ~11010~ | ~z~    |
#+begin_export html
</div>
#+end_export

Here's a breakdown of an example chromosome that could be used for that kind of word-based operating problem:

#+begin_center
[[file:images/blog/genetic_algorithm/chromosome_explanation.svg]]
#+end_center

The first gene in the above chromosome has the allele that represents the value "a".

Now for fitness. For whatever problem we want our algorithm to solve, we need to know what a good solution looks like because we need some way of knowing which organisms are better than others. The idea here is to come up with a way to *evaluate* each organism and give it a *fitness* score (a decimal number). The higher the fitness score, the closer the organism is to an ideal solution. It's difficult to be more descriptive than this because fitness evaluation varies a lot depending on the problem, so I'll explain by example.

Let's say the target problem is to find the best values for ~a~, ~b~, ~c~, and ~d~ in the equation ~a + 2b + 3c + 4d = 30~.[fn:5] Each organism's phenotype is its particular values for ~a~, ~b~, ~c~, and ~d~. The fitness evaluation for this problem could be:

#+begin_center
#+begin_example
1 / (abs((a + 2b + 3c + 4d) - 30) + 1)
#+end_example
#+end_center

Where ~abs~ gives the absolute value of a number. This evaluation is designed to give a higher fitness score for better values, with 1 being a perfect score. The range is ~(0, 1]~, meaning from 0 (exclusive) to 1 (inclusive).

So, an organism with the values ~a = 0~, ~b = 0~, ~c = 10~, and ~d = 0~ would have a fitness of 1...

#+begin_center
#+begin_example
1 / (((a + 2b + 3c + 4d) - 30) + 1)
= 1 / (((0 + 2(0) + 3(10) + 4(0)) - 30) + 1)
= 1 / (0 + 1)
= 1
#+end_example
#+end_center

...which is a perfect score! This makes sense, because these values perfectly satisfy the target equation.

#+begin_center
#+begin_example
a + 2b + 3c + 4d = 30
0 + 2(0) + 3(10) + 4(0) = 30
30 = 30
#+end_example
#+end_center

** Step 2. Setting parameters
:PROPERTIES:
:ID:       step-2
:END:

The algorithm has four major parameters that must be set. These will affect how well the algorithm performs each time it runs on a target problem. Once you've finished implementing your algorithm, these are the parameters you'll want to play with and see how it performs differently.

*** Population size

This is the number of organisms in the population for each generation. We'll call this parameter ~populationSize~.

A good starting point is ~populationSize = 50~.

*** Crossover rate

As pairs of organisms are selected to reproduce for the next generation, they may produce exact copies or be combined (like sexual reproduction in the real world). The crossover rate is the *probability* that each pair of selected organisms will be crossed over, which will be explained in Step 6. We'll call this parameter ~crossoverRate~.

A good starting point is ~crossoverRate = 0.6~.

*** Mutation rate

Every bit of information in every chromosome has a (low) chance to be mutated, which will be explained in Step 7. Mutations can spark new traits that can then be carried to future generations, adding diversity to the population. We'll call this parameter ~mutationRate~.

A good starting point is ~mutationRate = 0.05~.

*** Stopping condition

At some point, the algorithm has to stop, otherwise you've created an infinite loop! The easiest stopping condition to implement is to set a limit on the *number of generations*. When the limit is reached, take the organism with the highest fitness from the last generation's population and you have a solution!

Alternately, you could let the stopping condition be a *fitness threshold*. When a organism's fitness meets the threshold, halt and deem it the winner!

** Step 3. Create initial population

The first generation of organisms needs to come from somewhere. A good way to make the first population is to randomly generate every bit of information in every organism's chromosome until the number of organisms is equal to ~populationSize~. That way, all the organisms in the population will have completely random genes.

** Step 4. Fitness evaluation

Let the games begin! Evaluate the fitness of every organism in the population and store this information to be used in the next step.[fn:6]

** Step 5. Selection

This step begins the reproduction process (along with the next two steps). The current population needs to be used to form a new population (the next generation). Essentially, we're going to select pairs of organisms from the current population and have them reproduce to form offspring. Each pair will produce two offspring, and once we have enough offspring (determined by ~populationSize~), they will replace the current population.

Since the goal of the algorithm is to work towards a better solution, this step is where we simulate competition. In nature, not all members will reproduce equally---some will thrive and have lots of offspring while others will be less successful by comparison (due to death, inability to find a mate, etc.). Instead of just selecting organisms at random, the probability that an organism is selected should be proportional to its fitness. After all, this is the purpose of an organism's fitness! It should be more likely for high-performing organisms to be selected for reproduction than their lower-performing peers. For this, we're going to use the *roulette wheel* strategy.

Let's say we have a population of five organisms:

#+begin_export html
<div class="table-container">
#+end_export
| Organism                                              | Chromosome  | Fitness | Percent of population fitness |
|-------------------------------------------------------+-------------+---------+-------------------------------|
| @@html:<span style="color:#9933FF">&#9632;</span>@@ 1 | ~0011 0110~ |    0.23 |                          9.9% |
| @@html:<span style="color:#333333">&#9632;</span>@@ 2 | ~0001 1010~ |    0.68 |                         29.2% |
| @@html:<span style="color:#61C0FF">&#9632;</span>@@ 3 | ~1001 1011~ |     0.1 |                          4.3% |
| @@html:<span style="color:#17C22E">&#9632;</span>@@ 4 | ~1010 0111~ |    0.95 |                         40.8% |
| @@html:<span style="color:#EB0000">&#9632;</span>@@ 5 | ~0101 0010~ |    0.37 |                         15.9% |
#+begin_export html
</div>
#+end_export

(Don't pay much attention to the chromosome values in this example. I made them up randomly.)

At a casino, every segment of a roulette wheel is equal in size. But our goal is to make a rigged roulette wheel where the segments are proportional to their fitness:

#+begin_center
[[file:images/blog/genetic_algorithm/genetic_algorithm_roulette.png]]
#+end_center

Now, when we spin the wheel to select an organism, it's obvious there will be a bigger chance to land on *organism 4* than any other organism.

If you want more direct instructions on implementing the roulette wheel strategy in code, click/tap below. Or, you can enjoy devising the algorithm on your own!

#+begin_export html
<details>
<summary>Show roulette wheel instructions</summary>
#+end_export

To implement roulette wheel selection in code, this is what you need to do:

- (Your organisms must be kept in order. The way they're ordered doesn't matter, so long as the order doesn't change.)
- Calculate the total fitness of the population (sum the fitnesses of all organisms).
- Calculate the cumulative fitness of each organism. The cumulative fitness of an organism is its fitness plus the sum of the fitnesses of all the organisms before it.
- Generate a random number, ~r~, between 0 (exclusive) and the total fitness (inclusive).
- Find the first organism whose cumulative fitness is greater than or equal to ~r~.

For example, if we calculate the cumulative fitnesses of our organisms...

#+begin_export html
<div class="table-container">
#+end_export
| Organism | Chromosome  | Fitness | Cumulative fitness |
|----------+-------------+---------+--------------------|
|        1 | ~0011 0110~ |    0.23 |               0.23 |
|        2 | ~0001 1010~ |    0.68 |               0.91 |
|        3 | ~1001 1011~ |     0.1 |               1.01 |
|        4 | ~1010 0111~ |    0.95 |               1.96 |
|        5 | ~0101 0010~ |    0.37 |               2.33 |
#+begin_export html
</div>
#+end_export

...and if ~r~ turns out to be 1.89, that means we select *organism 4*.

#+begin_center
[[file:images/blog/genetic_algorithm/roulette_wheel_cumulative.svg]]
#+end_center

#+begin_export html
</details>
#+end_export

We have now met the overall goal of this step: to *select two organisms while accounting for their fitness*, which will be used in the next step to produce a pair of offspring.[fn:7]

** Step 6. Crossover

The purpose of this step is to involve an important aspect of natural selection: heredity. Offspring tend to resemble some combination of their parents (and diminishingly, their more distant ancestors). We're going to achieve this through reproduction by breeding or cloning. The offspring of the two previously selected organisms will either inherit a combination of their traits (genes from both parents) or be clones of the parents.

To check if a crossover should happen, generate a random number, ~r~, between 0 and 1. If ~r~ is less than or equal to ~crossoverRate~, perform a crossover. Otherwise, let the offspring be exact copies of the parents (put simply, the parents become the offspring).

To crossover two organisms, pick a random position between the genes of a chromosome and swap all the alleles to the right in the first chromosome with the corresponding alleles in the second chromosome. (Remember, our chromosomes are supposed to contain the same number of genes, so this makes it easy to line them up and cut them at the same spot.)

#+begin_center
[[file:images/blog/genetic_algorithm/crossover.svg]]
#+end_center

** Step 7. Mutation

Due to mutation in nature, novel or modified characteristics occasionally show up that do not appear to have belonged to an ancestor, but can still be passed on to offspring like any other trait. Combined with heredity, this suggests that a population has a capacity for change beyond just an endless recombination of preexisting traits. And due to fitness-based selection, occasionally a novel trait will arise that confers a competitive advantage (e.g., the organism that has that new trait is better able to survive and reproduce because of it). These traits will then enter and proliferate across the population through subsequent generations.

To simulate genetic mutation in code, we allow the newly formed offspring the potential to mutate. For each bit in each offspring's chromosome:

- Generate a random number, ~r~, between 0 and 1.
- If ~r~ is less than or equal to ~mutationRate~, mutate the bit. To mutate, simply flip the bit (~0~ to ~1~, or ~1~ to ~0~).

** Step 8. Replace population

Steps 5 to 7 (selection, crossover, and mutation) taken as a cycle together form the reproduction process. Each cycle produces two offspring. We need to repeat the cycle until we get enough offspring to form a new population (~populationSize~), which immediately replaces the old population. The old population won't be needed anymore (everything dies...). (For practical purposes, this means offspring never reproduce with the previous generation.)

** Step 9. Repeat until the stopping condition is met

As the gods of this artificial world of digital organisms, we decide when the simulation ends.

Steps 4 to 8 form the main loop of the algorithm. Each iteration of that loop is one generation. The planned stopping condition marks the end of the loop, which leaves us with the last generation's population. If the stopping condition is a limit on the number of generations, say 100, then we simply stop after repeating 100 iterations.

** Step 10. Pick the winner

In the remaining population, pick the organism with the highest fitness. There's your solution!

* A Target Problem

Just reading about genetic algorithms won't be enough to grasp this concept; you need to engage in implementing a genetic algorithm on your own. But first, you need the right kind of problem to solve. Lucky for you, I've got that part covered! In this section, I'm going to outline a problem and give you all the necessary details so you can start coding in any programming language you want. In other words, I'm going to cover *Step 1* (planning) and you have to do the rest.

** The Problem

Given a target number, find a human-readable string of single-digit numbers and basic arithmetic operators that equals that number. For example, if the target number is ~10~, some solutions would be:

- ~5 + 5~
- ~5 * 2~
- ~5 + 5 + 1 - 1 - 5 - 5 + 1 + 9 * 1 / 1~

*Note:* Because the solutions should take the form of math strings, you should decide how those strings get evaluated. For example, they could be evaluated left-to-right or use the standard order of operations (multiplication > division > addition > subtraction). Feel free to choose whichever evaluation method is easier for you to implement.

If we solve this problem using a genetic algorithm, since all of the above solutions equal 10 exactly, they would all be ideal matches and maximally fit. Of course, there are infinite possible solutions to reach any target number, and because our initial population is randomly generated, the algorithm may not discover /any/ of them in the limited time it has to run. So, the true goal of our genetic algorithm would be to give us the best candidate after a certain number of generations.

** Implementing Step 1. Planning

Since a potential solution is to be a string of single-digit numbers and arithmetic operators, that is exactly what a chromosome should represent. The genes, being pieces of a chromosome, should therefore each express a single-digit number or an arithmetic operator.

Now, instead of artificially forcing organisms to have alternating numbers and operators, let's allow any combinations of valid genes and instead do a sort of /clean up/ when evaluating their expression. In other words, ignore successive numbers (or operators) in a row, using only the first one that appears in order while alternating. For example, ~6 6 * 8 1 + 5 6 9 / 2 1~ /cleans up/ to be ~6 * 8 + 5 / 2~.

To determine gene size, we need to know how many possible alleles are necessary. In this case, the required alleles are all the single-digit numbers and arithmetic operators: ~0~, ~1~, ~2~, ~3~, ~4~, ~5~, ~6~, ~7~, ~8~, ~9~, ~+~, ~-~, ~*~, ~/~. That's fourteen possible alleles in total, so we need a minimum of four bits per gene (giving us 2^4 = 16 different possible alleles). We will have two left over alleles, but we can ignore them if they turn up in the resulting chromosome. So, our alleles are:

#+begin_export html
<div class="table-container">
#+end_export
| allele | value       |
|--------+-------------|
| ~0000~ | ~0~         |
| ~0001~ | ~1~         |
| ~0010~ | ~2~         |
| ~0011~ | ~3~         |
| ~0100~ | ~4~         |
| ~0101~ | ~5~         |
| ~0110~ | ~6~         |
| ~0111~ | ~7~         |
| ~1000~ | ~8~         |
| ~1001~ | ~9~         |
| ~1010~ | ~+~         |
| ~1011~ | ~-~         |
| ~1100~ | ~*~         |
| ~1101~ | ~/~         |
| ~1110~ | ~(junk)~ |
| ~1111~ | ~(junk)~ |
#+begin_export html
</div>
#+end_export

As an example, we could have the following organism's chromosome and its phenotype:

#+begin_center
#+begin_example
[0110 0110 1110 1100 1000 0001 1010 0101 0110 1001 1101 0010 0001]
= 6 6 (junk) * 8 1 + 5 6 9 / 2 1
= 6 * 8 + 5 / 2
= 50.5
#+end_example
#+end_center

Now, we need to determine how the fitness of an organism should be evaluated. Recall that that we need an evaluation function which produces a higher number for organisms that are closer to the ideal solution. Ideally, we should fit the fitness number into the range ~(0, 1]~, since this makes the roulette wheel selection easier. Try to come up with this function yourself, or click/tap to see my suggestion below (there's more than one right answer!).

#+begin_export html
<details>
<summary>Show fitness function</summary>
#+end_export

~fitness(phenotype) = 1 / abs((target - phenotype) + 1)~

Where ~phenotype~ is the evaluated expression of a given organism, ~target~ is the target number, and ~abs~ gives the absolute value of a number.

#+begin_export html
</details>
#+end_export

*Gotcha:* It is very possible for division by 0 to be part of a phenotype. I'll leave it up to you to decide how to handle it, but do expect it to happen and consider your options.

** Build it!

That's it! Now you're on your own to code this algorithm by implementing steps 2 through 10. In the end, you should have an app which, given a target number, produces a math expression for that number. Remember, if you're not getting good results, try tweaking the [[#step-2][parameters]].

* Food for Thought

** Why a chance of crossover?

Why is it important to have a chance of crossover /not/ happening? Suppose we have two organisms, Alice and Bob, selected to be parents. Alice's fitness is 99% and Bob's is 80%. If Alice and Bob are to produce offspring who inherit from both of them, the offspring are almost guaranteed to have a lower fitness than Alice's 99%. A preferable outcome would be for Alice's offspring to /exclusively/ contain her genes---without any crossover with Bob---resulting in a clone. (That final percentage point of fitness might be then achieved with a lucky mutation.)

** Selecting the same chromosome more than once?

/[To-do]/

** What does cloning represent?

When a crossover doesn't occur, the offspring are clones of the parents. What does it mean to produce clones? Are we simulating an organism that reproduces both sexually /and/ asexually? Or are we representing organisms that simply carry on living into the next generation?

** What are the traits?

In the real world, organisms can be described as having many traits. In the target problem described above, what are the traits of an organism? Do each of our organisms only have a single trait: its evaluated number? Or can we think of each expressed allele as a trait?

** When does crossover help?

In the target problem described above, does crossing over two high-fitness organisms have a good chance of producing high-fitness offspring? Swapping genes seems likely to drastically, and almost randomly, change a organism's phenotype. It seems more like mutating a chunk of a chromosome than inheriting traits.

** What are other ways of representing organisms in the target problem?

/To-do/

* Footnotes

[fn:1] Conversely, *artificial* selection occurs when populations are bred with intention to encourage or discourage particular traits (and therefore, "fitness" is externally, deliberately dictated).  Dog breeds and the modern forms of the fruits and vegetables we eat are classic examples of artificial selection.  (Incidentally, artificial selection in humans is called [[https://en.wikipedia.org/wiki/Eugenics][eugenics]], and is an endlessly fascinating ethical tire-fire.)

[fn:2] Species in nature are not as distinct as they're often presented and described, since "viability" of offspring can be a matter of degree (excluding cases like mules---horse/donkey hybrids that are born sterile), and can be subject to geographical boundaries.  One of the coolest examples I've encountered is the idea of [[https://en.wikipedia.org/wiki/Ring_species][ring speciation]]: imagine a migrating population that arrives at an impassible barrier like a lake or a mountain, and begins to spread around it.  Over multiple generations, local portions of that larger population will be subject to different selection pressures, resulting in local variations building up (and associated, accumulating genetic differences when comparing parts of the population that went one way when it met the barrier, vs. the other).  If the expanding population meets up again on the other side of the barrier (i.e., "closing the ring"), it's possible that members of the two sides will have built up enough differences that they'll no longer be genetically compatible with one another---/they'll be different species, by this definition/.  Yet, if you were to take sample organisms at smaller geographic intervals, travelling back around that ring from one end to the other, they /would/ be able to interbreed.  Speciation as a gradient!  I love it.

[fn:3] Richard Dawkins, before his association with atheism, arguably became a household name for his book /The Selfish Gene/, wherein he explored a fascinating extension of this process and imagined the machinery of organisms---cells, blood, eyes, locomotion, intelligence, tentacles, etc.---as mere vehicles for individual genes to improve their chances of propagation.  It was a fun read, and pre-Creationist-beleaguered Dawkins had a spark of eager excitement that came out in his footnotes especially, that I think the vagaries of the world eventually ground away.  Alas.

[fn:4] /Capacity/ to speak a language /largely/ is (i.e., no cactus is likely to ever speak Urdu no matter how much expert tutelage it has access to, while humans do it all the time); /capacity to speak a language comparatively well/ is extremely complicated, increasingly becoming an interaction between the individual's heredity and its lived experience...

[fn:5] Example borrowed from: Hermawanto, D. (2013). Genetic algorithm for solving simple mathematical equality problem. arXiv preprint [[https://arxiv.org/pdf/1308.4675.pdf][arXiv:1308.4675]].

[fn:6] This is arguably an implementation detail pertaining to optimization via caching, but I see it as having conceptual importance. The fitness of an organism never changes because its genetics don't change and the operating problem doesn't change. This is different from how we might talk about people's physical fitness, where you can become more fit by working out. Since we're simulating natural selection and treating environmental factors as being constant, fitness is tied to the genetics of an organism, which are fixed. The only changes to genetics happen between generations (i.e., during reproduction). So, with fitness being an unchanging value of an organism, it should be evaluated exactly once per organism.

[fn:7] Note that this allows for the same organism to be selected more than once. That's okay! Organisms with higher fitness being allowed to reproduce multiple times is part of natural selection. Less fit individuals may not be selected to breed at all, allowing their less-desirable traits to simply die out.

[fn:9] Goldberg, David (1989). Genetic Algorithms in Search, Optimization and Machine Learning. Reading, MA: Addison-Wesley Professional. ISBN 978-0201157673.

[fn:8] https://en.wikipedia.org/wiki/Genetic_algorithm#History
